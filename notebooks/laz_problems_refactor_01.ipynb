{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe16cf6c",
   "metadata": {},
   "source": [
    "## Lidar Metadata Extraction and EDA Notebook\n",
    "\n",
    "This notebook is designed for rapid, robust analysis of lidar .laz tiles, including:\n",
    "- Extraction of per-tile and per-class summary statistics (e.g. point density, ground fraction, scan angle, etc)\n",
    "- Flexible input: process entire dataset, a subset (by class), or use provided summary CSVs\n",
    "- Optional: geospatial visualizations of density and overlaps\n",
    "\n",
    "USAGE:\n",
    "- By default, skips heavy processing and only loads summary for EDA.\n",
    "- To process your own files (all or a subset), set RUN_PROCESSING = True and configure input locations.\n",
    "\n",
    "CONFIG OPTIONS:\n",
    "- RUN_PROCESSING: Set to True to run metadata extraction on raw .laz files; otherwise, just load outputs.\n",
    "- PROCESS_CLASSES: List of class names (e.g. ['RIB_A01', 'BON_A01']) to process if processing subset. Set to None to process all.\n",
    "- PATHS: Edit local/Kaggle paths as needed.\n",
    "\n",
    "Requirements: laspy, pandas, numpy, geopandas (optional: folium), tqdm.\n",
    "\n",
    "Author: Seamus Barnes\n",
    "\n",
    "Date: 2025-06-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d6e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- CONFIG ----\n",
    "\n",
    "# Main flag: skip .laz processing for fast EDA, or process files yourself?\n",
    "RUN_PROCESSING = False      # Set to True to extract metadata from your .laz files\n",
    "PROCESS_CLASSES = None      # List of class names to process, e.g. ['RIB_A01', 'BON_A01']. None = all classes.\n",
    "\n",
    "# Data locations (edit if using locally, or add extra Kaggle `/kaggle/input/yourdataset`)\n",
    "DATA_RAW_LAZ_DIRS = [\n",
    "    \"../input/kaggle-dataset1-laz\",  # <- put the correct Kaggle dataset names / paths here!\n",
    "    \"../input/kaggle-dataset2-laz\",\n",
    "    \"../input/kaggle-dataset3-laz\",\n",
    "    \"../input/kaggle-dataset4-laz\"\n",
    "]\n",
    "\n",
    "# WHERE TO EXPECT/WRITE OUTPUT CSVs:\n",
    "# By default, will use pre-made outputs in ../input/precomputed-metadata/...\n",
    "# If processing yourself, will also save to the same names in ../working/ for future download\n",
    "\n",
    "# Precomputed paths (for fast EDA, use these if present)\n",
    "import os\n",
    "CWD = os.getcwd()\n",
    "PATH_METADATA_CSV_INPUT = os.path.join(CWD,\"input/precomputed-metadata/lidar_metadata_full.csv\")\n",
    "PATH_CLASS_SUMMARY_CSV_INPUT = os.path.join(CWD,\"input/precomupted_metadata/lidar_metadata_full.csv\")\n",
    "\n",
    "# Where to write new files if running processing\n",
    "PATH_METADATA_CSV_OUTPUT = \"lidar_metadata_full.csv\"\n",
    "PATH_CLASS_SUMMARY_CSV_OUTPUT = \"lidar_metadata_class_summary.csv\"\n",
    "\n",
    "# Save progress every N files if running processing\n",
    "SAVE_INTERVAL = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7fb0d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:46:00) [Clang 18.1.8 ]\n",
      "laspy version: 2.3.0\n",
      "geopandas version: 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union\n",
    "import folium\n",
    "import branca.colormap as cm\n",
    "\n",
    "# Lidar file reading\n",
    "try:\n",
    "    import laspy\n",
    "except ImportError:\n",
    "    print(\"ERROR: laspy is required for .laz file processing. Please install with `pip install laspy`.\")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Print environment info for debug ---\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"laspy version: {getattr(laspy, '__version__', 'N/A')}\")\n",
    "if gpd:\n",
    "    print(f\"geopandas version: {gpd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d61e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Block 3: File Discovery & Class Selection Helpers\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def find_laz_files(laz_dirs, exts=(\".laz\", \".LAS\", \".las\")):\n",
    "    \"\"\"\n",
    "    Find all .laz/.las files in provided input directories (recursively).\n",
    "    Args:\n",
    "        laz_dirs: List of directory paths.\n",
    "        exts: Allowed file extensions.\n",
    "    Returns:\n",
    "        files: List of file paths (full path)\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for dir in laz_dirs:\n",
    "        if not os.path.exists(dir):\n",
    "            print(f\"Warning: Directory does not exist: {dir}\")\n",
    "            continue\n",
    "        for ext in exts:\n",
    "            files_found = glob.glob(os.path.join(dir, f\"**/*{ext}\"), recursive=True)\n",
    "            files.extend(files_found)\n",
    "    print(f\"Found {len(files):,} .laz/.las files in input directories.\")\n",
    "    return files\n",
    "\n",
    "def get_class_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse 'class' (first two underscore-separated fields) from lidar filename, e.g. JAM_A02_2011_laz_4.laz -> 'JAM_A02'\n",
    "    \"\"\"\n",
    "    return \"_\".join(os.path.basename(filename).split(\"_\")[:2])\n",
    "\n",
    "def filter_files_by_class(files, allowed_classes):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        files: List of full file paths.\n",
    "        allowed_classes: List of allowed class names (e.g., ['RIB_A01', ...])\n",
    "    Returns:\n",
    "        filtered_files: List of file paths with class in allowed_classes.\n",
    "    \"\"\"\n",
    "    if allowed_classes is None:\n",
    "        return files\n",
    "    filtered_files = [f for f in files if get_class_from_filename(f) in allowed_classes]\n",
    "    print(f\"Filtering for classes={allowed_classes}: {len(filtered_files):,} files selected.\")\n",
    "    return filtered_files\n",
    "\n",
    "# ---- Example usage (don't run yet, run in processing block):\n",
    "# all_laz_files = find_laz_files(DATA_RAW_LAZ_DIRS)\n",
    "# subset_laz_files = filter_files_by_class(all_laz_files, PROCESS_CLASSES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Conda, openai_to_z)",
   "language": "python",
   "name": "openai_to_z"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
